<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <link rel="stylesheet" type="text/css" href="../base.css">
    <link rel="stylesheet" type="text/css" href="visual.css">
  </head>

  <body class="thinking">

      <div class="hide-the-text-from-view-because-im-going-to-read-it-in-the-browser-inspector">
        <div class="show-this">
          <iframe src="../code-societies-archive/pages/16.html" width="100%"></iframe>
          <iframe src="../code-societies-archive/pages/11.html" width="100%"></iframe>
        </div>
        When I first started to put together this workshop in 2019, I had been thinking a lot about computation and metaphor. More specifically how the metaphor of the desktop was claimed along with the personal computer as “for everyone” but really it was for everyone who was already familiar with the system of the office.
        <br>
        <br>


        And to this day I am perpetually perplexed that nearly everything I do as a programmer is somehow removed from what my computer is physically doing and instead I am always working within sets of metaphors, and with them sets of ideologies, to remember and understand how to do those things within this visual interface of the desktop that were all looking into right. I first read Wendy Chun’s essay “On Software, or the Persistence of Visual Knowledge” in a class taught by American Artist and it really opened up the history of computing for me in a way that I hadn’t really expected it to. In discussing software as ideology Chun writes “Software, or perhaps more precisely operating systems, offer us an imaginary relationship to our hardware: they do not represent transistors but rather desktops and recycling bins. Software produces ‘users.’”
        <br>
        <br>


        My own current research focuses on the history of the computer mouse and I have found it helpful to look at this history of computers, this history of, in Chun’s words, “ideology machines” in order to understand how in one way or another we got to the computers we are all using today. There is so much history there but for now I’m going to share with you a small pre-history of the computer mouse and the personal computer. This is kind of a roundabout way to get to hand coding but for me they are philosophically and materially intertwined.
        <br>
        <br>


        Input devices (the mouse, stylus pens, light guns) are rooted in the emergence of screen technology. This is long before the technology of touch, in which the hand became the input device itself. Early screen technology saw a long line of input devices used for pointing, tracking, choosing, and classifying.
        <br>
        <br>


        The origins of the input device being an input device as we know it belong to the Whirlwind computer, invented in 1951. The Whirlwind, was a Cold War computing machine and it was the first computer to make its calculations in real time.4 Before the Whirlwind, computers would take long periods of time to process a program, requiring the physical adjustment of switches or punched cards to run the program again. Originally designed as a flight simulator, the Whirlwind was able to receive inputs and produce outputs using a three-dimensional array of magnetic core memory, an extremely efficient organization of physical computing components which allowed for fast storing and retrieval of data.6 This technology would help to create the cathode ray tube screen. Jacob Gaboury on the history of the computer screen writes “The screen is not simply an enduring technique or evocative metaphor; it is a hardware object whose transformations have shaped the material conditions of our visual culture.”
        <br>
        <br>


        Because cathode ray tube screens, standardized by the 1950s, transformed ones and zeroes into light and in real time, they required an input device which shared the language of light as signal. The team behind the Whirlwind came up with an input device using this language of light and this is where the mouse’s predecessor, the light pen, materialized.8 At the time of the light pen, computers were already much more than calculating machines, but they were not yet ubiquitously used for purposes outside of the military. The screen was still thought of as a substrate like paper, the analog substrate for tracking and storing, and the light pen was the next best iteration of moving from the analog act of writing to the digital act of pointing. In this sense, the problem of computing became not only the act of programming switches but also the act of moving on along x and y coordinates.
        <br>
        <br>


        By the 1960’s research towards the project of what computers could do, towards computational intelligence, had forked.1 In one direction the idea was to build up an autonomous intelligence that would match or even supersede human intelligence. The question, by the way, of “what intelligence actually is” still stands and in my opinion artificial intelligence has proven to show us more often what intelligence is not than what it is. In the other direction, a person named Douglas Engelbart led a research lab called the Augmentation of Human Intellect which sought to create a kind of intelligent symbiosis between the human and the computer.
        <br>
        <br>


        It is in between the human and the computer where the mouse, made for the human hand, first materialized. Invented by Engelbart in 1964 the mouse was but a small part of a much larger invention and this invention was called the oN-Line System. Presented to the public as what later became known as “the mother of all demoes” the system that Engelbart had built and performed included some of the earliest versions of hyperlinks, multiple windows, real-time cross-computer collaboration (which is what we will be doing today), and finally, the use of a mouse. It was amalgamation of devices, all situated within optimal distance for the hand to the mouse, the eyes to the screen.
        <br>
        <br>


        In 1971, eight years after its invention, Engelbart’s colleague took the mouse to a research lab called  Xerox PARC and re-developed the original mouse so that it could be used alongside the first personal computer, the Xerox Alto.3 We can thank the Xerox Alto, a computer that heavily inspired the Steves of Silicon Valley, for the desktop metaphor. Ok so here we are, back to the screen, back to the desktop. The mouse brought us here. All of your office needs could be met by a series of keystrokes and clicks. At this point, the mouse had become the standard input device for computing and was synonymous not only with interactivity and collaboration but also with work.
        <br>
        <br>


        This desktop metaphor ensured that computers require programming, as we know it today, to be a set of extremely abstract processes. So, when I’m coding something, I’m often coding on top of someone else’s code, in someone else’s software, on top of the software that makes up my operating system which is permanently baked into the proprietary silicon chip of my Apple computer.
        <br>
        <br>


        Computers at their core still consist of a complex series of on and off switches, ones and zeroes except now the switches are like an extremely tiny mix of analog and digital signals and are nearly invisible to the human eye. This means that everything we do on our computers today is already abstracting away those complex patterns of numbers in order for us to use them in the way that we do. So these abstractions allow us to do things like writing text in a file, without thinking about how or even if the computer will be able to do this.
        <br>
        <br>


        I think it is important to note that since the early days of computing computer time has always been more important than human time. When programmers were writing code for computers the size of rooms the time it took to run the program was really expensive, so people were always writing code that was most efficiently read by the computer itself not by the people who were making the programs. This reflects our current moment of computing where code is written in often illegible jargon and minified into unreadable blobs of text. This is why coding is intimidating, it seems to be a problem of language, some kind of insider’s club, but really it’s just been purposefully abstracted and a lot of the original languages from the 70s, 80s and 90s are still the foundation upon which so much code is written.
        <br>
        <br>


        As an example, today when someone builds a website the might use a mix of languages like Ruby, JavaScript and Python and then uses a mix of libraries and frameworks which someone else has written to compile all of it’s into the only three readable languages by the browser HTML, CSS, and JavaScript all of which haven’t changed in any major way since the mid 90s.
        <br>
        <br>


        Going back to this idea of the desktop metaphor. The idea of a file inside a folder on a desktop...and then there's the trashcan. I’m always wondering, when you put something in the trash, does it ever really go away? And what is the file really? And what is the folder? a computer scientist friend once told me that folders aren't actually anything. They don't take up *any* space on your computer. This might sound familiar to those of you who have been working on folder poetry in this class. I often reflect on something Kameelah Janan Rasheed once said in a class she taught, how analogies can be a poverty of language. In step with this provocation I am always wondering how the metaphors of files and folders limited our imagination for what computing can be? If not for the baked in interface of the desktop what might we put on a screen emitting light? Or to think about it in a different way, what would it be like if we could hear all of the computation happening inside our laptops as we typed out an email? How might we think about computing differently?
        <br>
        <br>


        This is all just to interrogate the fact that there has been a significant shift from physical programming, the act of physically adjusting switches or weaving software into core rope memory to abstracted programming, building software on top of software. Since folders and files, which if we looked closely at them don’t resemble anything close to a piece of paper inside another folded piece of paper, I’m left wondering does the way that we use our computers also require some kind of illusion of control over our computers. The key word here being illusion.
        <br>
        <br>


        Programmers, through the creation of complex frameworks and algorithmic systems go through so many hurdles trying to get the computer to do what they want it to do. When the computer finally obeys their commands, they are granted with this feeling of immense gratification and power. I’ve felt this feeling of gratification as a programmer after hours and hours of trying to debug something I wrote. It’s a cyclical command and response from you to your computer. My provocation here is not to call for an undoing of this cycle of command and response (although I’m interested in that) but to become aware of what is happening in between. So instead of humans controlling computers and computers controlling humans I am interested in how computers can be between, not over or under, the people that use them.
        <br>
        <br>


        This is a video of my grandma writing an email to someone. It makes me wonder what it would be like if programmers had to press the keys of their keyboards so gently that it required them to move extremely slow and therefore with care? And so, all of these questions have led me to care deeply about hand coding. Hand coding is the process of coding that bridges the gap between you and the browser. In other words, it is a way to code which is not dependent on someone else’s software or framework or library, you are writing in the language that the browser understands, and the language that has been used since the 90s to make websites.
        <br>
        <br>


        So I’m kind of lying to you here because your browser is software but hand coding in the software of the browser is what I like to call closer to the metal of your computer then doing something like making a Wordpress website which is software on a big server depending on fragile code written by tons and tons of people and then minified into HTML CSS and Javascript. Not that this is bad or good but I’m interested in questioning relationships around the transparency, encoding and decoding, file systems, and proprietaryness of computing and doing something like hand coding is a step towards new questions about our relationships to these things. The page we are looking at is from this past January when I led this workshop at Code Societies. So the browser is software which translates HTML and CSS into web pages. Your browser is the performer of the program you are writing.
        <br>
        <br>


        The code you will write in this workshop will be very particular and you will write out each character slowly and by hand, there will be very little copying or pasting. We’ll move as slow as we want to and I will also be writing all the code out with you on my screen. You will also be coding on each other pages. The intention here is to perhaps erode this feeling of ultimate control that you have over your computer's system (or in the case of this online session, your web page) and to move carefully around someone else's. So, in this session we will be in discussion with each other not necessarily in a verbal way. Instead we’re going to be in conversation through the things we are writing on each other’s pages.
        <br>
        <br>
      </div>
  </body>
</html>
